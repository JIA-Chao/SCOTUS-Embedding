{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from textacy.datasets.supreme_court import SupremeCourt\n",
    "# from pytorch_pretrained_bert import BertModel, BertTokenizer\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sc.info:  {'name': 'supreme_court', 'site_url': 'http://caselaw.findlaw.com/court/us-supreme-court', 'description': 'Collection of ~8.4k decisions issued by the U.S. Supreme Court between November 1946 and June 2016.'}\n"
     ]
    }
   ],
   "source": [
    "sc = SupremeCourt()\n",
    "# sc.download()\n",
    "print('sc.info: ', sc.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([-1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.issue_area_codes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-1': 0,\n",
       " '1': 1,\n",
       " '2': 2,\n",
       " '3': 3,\n",
       " '4': 4,\n",
       " '5': 5,\n",
       " '6': 6,\n",
       " '7': 7,\n",
       " '8': 8,\n",
       " '9': 9,\n",
       " '10': 10,\n",
       " '11': 11,\n",
       " '12': 12,\n",
       " '13': 13,\n",
       " '14': 14}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue_codes = list(sc.issue_area_codes.keys()) # 15 labels\n",
    "issue_codes.sort()\n",
    "issue_codes = [str(ic) for ic in issue_codes]\n",
    "# issue_codes\n",
    "\n",
    "# dictionary mapping label name to numeric id\n",
    "labels_index = dict(zip(issue_codes, np.arange(len(issue_codes))))\n",
    "labels_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- The format of one record ---------\n",
      "length:  2\n",
      "tempRecord[0] is the text:  <class 'str'>\n",
      "tempRecord[1] is the dict:  {'issue': '80180', 'issue_area': 8, 'n_min_votes': 1, 'case_name': 'HALLIBURTON OIL WELL CEMENTING CO. v. WALKER et al., DOING BUSINESS AS DEPTHOGRAPH CO.', 'maj_opinion_author': 78, 'decision_date': '1946-11-18', 'decision_direction': 'liberal', 'n_maj_votes': 8, 'us_cite_id': '329 U.S. 1', 'argument_date': '1946-01-09'}\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the format of the data.\n",
    "\n",
    "tempRecord = next(sc.records())\n",
    "type(tempRecord)\n",
    "\n",
    "print('--------- The format of one record ---------')\n",
    "print('length: ', len(tempRecord))\n",
    "print('tempRecord[0] is the text: ', type(tempRecord[0]))\n",
    "print('tempRecord[1] is the dict: ', tempRecord[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8419 texts.\n",
      "Found 15 labels.\n",
      "temp_count:  0\n",
      "length of cite_id_list:  8419\n",
      "length of cite_id_set:  3440\n",
      "length of case_name_plus_citeId_list:  8419\n",
      "length of case_name_plus_citeId_set:  6857\n"
     ]
    }
   ],
   "source": [
    "texts = []  # list of text samples\n",
    "labels = []  # list of label ids\n",
    "temp_count = 0\n",
    "cite_id_list = []\n",
    "\n",
    "case_name_plus_citeId_list = []\n",
    "\n",
    "for record in sc.records():\n",
    "    text_record = record[0]\n",
    "    feature_record = record[1]\n",
    "\n",
    "    # process issue number\n",
    "    issue_record = feature_record['issue']\n",
    "    if issue_record == None: # some cases have None as an issue\n",
    "        labels.append(labels_index['-1'])\n",
    "        issue_record = 'None_'\n",
    "    else:\n",
    "        labels.append(labels_index[feature_record['issue'][:-4]])\n",
    "    \n",
    "    # process case name\n",
    "    case_name_record = feature_record['issue']\n",
    "    if case_name_record == None:\n",
    "        case_name_record = 'None_'\n",
    "    \n",
    "    \n",
    "    # process cite id\n",
    "    cite_id_record = feature_record['case_name'][:5]\n",
    "    if cite_id_record == None:\n",
    "        temp_count += 1\n",
    "        cite_id_record = 'None'\n",
    "    else:\n",
    "        cite_id_list.append(cite_id_record)\n",
    "    \n",
    "    # add texts\n",
    "    texts.append(text_record)\n",
    "    \n",
    "    case_name_plus_citeId_list.append(issue_record+case_name_record+cite_id_record)\n",
    "\n",
    "print('Found %s texts.' % len(texts))\n",
    "print('Found %s labels.' % len(set(labels)))\n",
    "print('temp_count: ', temp_count)\n",
    "\n",
    "print('length of cite_id_list: ', len(cite_id_list))\n",
    "cite_id_set = set(cite_id_list)\n",
    "print('length of cite_id_set: ', len(cite_id_set))\n",
    "\n",
    "print('length of case_name_plus_citeId_list: ', len(case_name_plus_citeId_list))\n",
    "case_name_plus_citeId_set = set(case_name_plus_citeId_list)\n",
    "print('length of case_name_plus_citeId_set: ', len(case_name_plus_citeId_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I have tried several approaches using cases own information to generate the file name, but it seems we cannot do this way. Then the best approach is to assign file name ourselves and build a corresponding dictionary (map table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "2\n",
      "{'issue': '80180', 'issue_area': 8, 'n_min_votes': 1, 'case_name': 'HALLIBURTON OIL WELL CEMENTING CO. v. WALKER et al., DOING BUSINESS AS DEPTHOGRAPH CO.', 'maj_opinion_author': 78, 'decision_date': '1946-11-18', 'decision_direction': 'liberal', 'n_maj_votes': 8, 'us_cite_id': '329 U.S. 1', 'argument_date': '1946-01-09'}\n"
     ]
    }
   ],
   "source": [
    "for record in sc.records():\n",
    "    print(type(record))\n",
    "    print(len(record))\n",
    "    print(record[1])\n",
    "#     print(record['issue'])\n",
    "    break\n",
    "#         if record['issue'] == None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the text and issue number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/misc/grice1/yijun/SCOTUS-Embedding/data/supreme_court_8K/SPEIGHT, T/A HAREM BOOK STORE, et al. v. SLATON et al..txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a8d2131fae3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#     print(saved_files_path+file_name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# save to local\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_files_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/misc/grice1/yijun/SCOTUS-Embedding/data/supreme_court_8K/SPEIGHT, T/A HAREM BOOK STORE, et al. v. SLATON et al..txt'"
     ]
    }
   ],
   "source": [
    "saved_files_path = '/misc/grice1/yijun/SCOTUS-Embedding/data/supreme_court_8K/'\n",
    "count = 0\n",
    "\n",
    "for record in sc.records():\n",
    "    count += 1\n",
    "    text_record = record[0]\n",
    "    feature_record = record[1]\n",
    "#     if feature_record['issue'] == None: # some cases have None as an issue\n",
    "#         file_name = 'None_' + feature_record['case_name']\n",
    "#     else:\n",
    "#         file_name = feature_record['issue']\n",
    "#         issue_count += 1\n",
    "    file_name = feature_record['case_name'] + '.txt'\n",
    "    \n",
    "#     print(saved_files_path+file_name)\n",
    "    # save to local\n",
    "    with open(saved_files_path+file_name, 'w') as f:\n",
    "        f.write(text_record)\n",
    "\n",
    "print('count: ', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
