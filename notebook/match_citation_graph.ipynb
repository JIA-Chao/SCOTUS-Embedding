{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from textacy.datasets.supreme_court import SupremeCourt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "# from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "# from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "# from keras.layers import Dropout\n",
    "# from keras.models import Model, Sequential\n",
    "# from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.python.lib.io import file_io\n",
    "from time import gmtime, strftime\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which device are we in:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_checkPoint_path = '../ModelCheckpoint'\n",
    "VALIDATION_SPLIT = 0.1\n",
    "BATCH_SIZE = 32\n",
    "MAX_NB_WORDS = 170000\n",
    "EMBEDDING_DIM = 300\n",
    "learning_rate = 1e-4\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('which device are we in: ', device) # cuda:0 means we do have a gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors ...\n",
      "Found 3000000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained embedding\n",
    "print('Indexing word vectors ...')\n",
    "embeddings_index = {}\n",
    "embedding_path = '../data/GoogleNews-vectors-negative300.txt'\n",
    "# f = file_io.FileIO('../data/GoogleNews-vectors-negative300.txt', mode='r')\n",
    "with open(embedding_path, 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "# f.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset\n",
      "{'name': 'supreme_court', 'site_url': 'http://caselaw.findlaw.com/court/us-supreme-court', 'description': 'Collection of ~8.4k decisions issued by the U.S. Supreme Court between November 1946 and June 2016.'}\n",
      "Found 8419 texts.\n",
      "Found 15 labels.\n"
     ]
    }
   ],
   "source": [
    "print('Processing text dataset')\n",
    "\n",
    "sc = SupremeCourt()\n",
    "print(sc.info)\n",
    "\n",
    "texts = []  # list of text samples\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []  # list of label ids\n",
    "\n",
    "issue_codes = list(sc.issue_area_codes.keys()) # 15 labels\n",
    "issue_codes.sort()\n",
    "issue_codes = [str(ic) for ic in issue_codes]\n",
    "\n",
    "labels_index = dict(zip(issue_codes, np.arange(len(issue_codes))))\n",
    "\n",
    "for record in sc.records():\n",
    "    if record[1]['issue'] == None: # some cases have None as an issue\n",
    "        labels.append(labels_index['-1'])\n",
    "    else:\n",
    "        labels.append(labels_index[record[1]['issue'][:-4]])\n",
    "    texts.append(record[0])\n",
    "\n",
    "print('Found %s texts.' % len(texts))\n",
    "print('Found %s labels.' % len(labels_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ Halliburton Oil Well Cementing Co. v. Walker Mr.Earl Babcock, of Duncan, Okl. (Harry C. Robb, of Washington, D.C., on the brief), for petitioner.\\n Mr. Harold W. Mattingly, of Los Angeles, Cal., for respondents.\\n Mr. Justice BLACK delivered the opinion of the Court.\\n Cranford P. Walker, owner of Patent No. 2,156,519, and the other respondents, licensees under the patent, brought this suit in a federal district court alleging that petitioner, Halliburton Oil Well Cementing Company, had infringed certain of the claims of the Walker patent. The district court held the claims in issue valid and infringed by Halliburton. The circuit court of appeals affirmed, 9 Cir., 146 F.2d 817, and denied Halliburton\\'s petition for rehearing. 149 F.2d 896. Petitioner\\'s application to this Court for certiorari urged, among other grounds, that the claims held valid failed to make the \\'full, clear, concise, and exact\\' description of the alleged invention required by Rev.Stat. 4888C. 33, 35 U.S.C.A. 33,1 as that statute was interpreted by us in General Electric Co. v. Wabash Appliance Corporation, .2 This statutory requirement of distinctness and certainty in claims is important in patent law. We granted certiorari to consider whether it was correctly applied in this case. .3\\n The patent in suit was sustained as embodying an improvement over a past patent of Lehr and Wyatt (No. 2,047,974) upon an apparatus designed to facilitate the pumping of oil out of wells which do not have sufficient natural pressures to force the oil to gush. An outline of the background and setting of these patents is helpful to an understanding of the problem presented.\\n In order to operate a pump in an oil well most efficiently, cheaply, and with the least waste, the pump must be placed in an appropriate relationship to the fluid surface of the oil. Properly to place the pump in this relationship requires knowledge of the distance from the well top to the fluid surface. At least by the latter 1920\\'s problems of waste and expense in connection with non-gusher oil wells pressed upon the industry. See Railroad Commission of Texas v. Rowan & Nichols Oil Co., ; Burford v. Sun Oil Co., . It became apparent that inefficient pumping, one cause of waste, was in some measure attributable to lack of accurate knowledge of distance from well top to fluid surface. Ability to measure this distance in each separate non-gusher oil well became an obvious next step in the solution of this minor aspect of the problem of waste.\\n The surface and internal machinery and the corkscrew conformation of some oil wells make it impractical to measure depth by the familiar method of lowering a rope or cable. In casting about for an alternative method it was quite natural to hit upon the possibility of utilizing a sound-echo- time method. Unknown distances had frequently been ascertained by this method. Given the time elapsing between the injection of a sound into an oil well and the return of its echo from the fluid surface, and assuming the velocity of the sound to be about 1,100 feet per second, as it is in the open air, it would be easy to find the distance. Not only had this sound-echo-time method been long known and generally used to find unknown distances, but in 1898 Batcheller, in Patent No. 602,422, had described an apparatus to find a distance in a tubular space. Obviously an oil well is such a space. He described a device whereby the noise from a gun might be injected into a tube; the returning echoes from obstructions agitated a diaphragm, which in turn moved a stylus. The stylus recorded on a piece of paper a graph or diagram showing the variant movements of the diaphragm caused by its response to all the different echo waves.\\n In the late 1920\\'s the oil industry began to experiment in the use of this same sound-echo-time method for measur- ing the distance to the fluid surface in deep oil wells. A product of this experimentation was the Lehr and Wyatt patent, upon which the present patent claims to be an improvement. It proposed to measure the distance by measuring the time of travel of the echo of \\'an impulse wave\\' generated by a \\'sudden change in pressure.\\' The apparatus described included a gas cylinder with a quick operating valve by means of which a short blast of gas could be injected into a well. It was stated in the patent that the time elapsing between the release of the gas and the return of the echo of the waves produced by it could be observed in any desired manner. But the patentee\\'s application and drawings noted that the wave impulses could be recorded by use of a microphone which might include an amplifier and an appropriate device to record a picture of the wave impulses.\\n This Lehr and Wyatt patent, it is therefore apparent, simply provided an apparatus composed of old and well-known devices to measure the time required for pressure waves to move to and back from the fluid surface of an oil well. But the assumption that sound and pressure waves would travel in oil wells at open-air velocity of 1,100 feet per second proved to be erroneous. For this reason the timevelocity computation of Lehr and Wyatt for measuring the distance to the fluid surface produced inaccurate results.\\n After conferences with Lehr, Walker undertook to search for a method which would more accurately indicate the sound and pressure wave velocity in each well. Walker was familiar with the structure of oil wells. The oil flow pipe in a well, known as a tubing string, is jointed and where these joints occur there are collars or shoulders. There are also one or more relatively prominent projections on the oil flow pipe known as tubing catchers. In wells where the distance to the tubing catcher is known, Walker observed that the distance to the fluid surface could be measured by a simple time-distance proportion formula. 4\\n For those wells in which the distance to the tubing catcher was unknown, Walker also suggested another idea. The sections of tubing pipe used in a given oil well are generally of equal length. Therefore the shoulders in a given well ordinarily are at equal intervals from each other. But the section length and therefore the interval may vary from well to well. Walker concluded that he could measure the unknown distance to the tubing catcher if he could observe and record the shoulder echo waves. Thus multiplication of the number of shoulders observed by the known length of a pipe section would produce the distance to the tubing catcher. With this distance, he could solve the distance to the fluid surface by the same proportion formula used when the distance to the tubing catcher was a matter of record. The Lehr and Wyatt instrument could record all these echo waves. But the potential usefulness of the echoes from the shoulders and the tubing catcher which their machine recorded had not occurred to Lehr and Wyatt and consequently they had made no effort better to observe and record them. Walker\\'s contribution which he claims to be invention was in effect to add to Lehr and Wyatt\\'s apparatus a well-known device which would make the regularly appearing shoulder echo waves more prominent on the graph and easier to count.\\n The device added was a mechanical acoustical resonator. This was a short pipe which would receive wave impulses at the mouth of the well. Walker\\'s testimony was, and his specifications state, that by making the length of this tubal resonator one-third the length of the tubing joints, the resonator would serve as a tuner, adjusted to the frequency of the shoulder echo waves. It would simultaneously amplify these echo waves and eliminate unwanted echoes from other obstructions thus producing a clearer picture of the shoulder echo waves. His specifications show, attached to the tubal resonator, a coupler, the manipulation of which would adjust the length of the tube to one-third of the interval between shoulders in a particular well. His specifications and drawings also show the physical structure of a complete apparatus, designed to inject pressure impulses into a well, and to receive, note, record and time the impulse waves.\\n The District Court held the claims here in suit valid upon its finding that Walker\\'s \\'apparatus differs from and is an improvement over the prior art in the incorporation in such apparatus of a tuned acoustical means which performs the functions of a sound filter ....\\' The circuit court of appeals affirmed this holding, stating that the trial court had found \\'that the only part of this patent constituting invention over the prior art is the \\'tuned acoustical means which performs the functions of a sound filter.\"\\n For our purpose in passing upon the sufficiency of the claims against prohibited indefiniteness we can accept without ratifying the findings of the lower court that the addition of \\'(a) tuned acoustical means\\' performing the \\'functions of a sound filter\\' brought about a new patentable combination, even though it advanced only a narrow step beyond Lehr and Wyatt\\'s old combination. 5 We must, however, determine whether, as petitioner charges, the claims here held valid run afoul of Rev.Stat. 4888 because they do not describe the invention but use \\'conveniently functional language at the exact point of novelty.\\' General Electric Co. v. Wabash Appliance Corporation supraat page 371, 58 S.Ct. at page 903\\n Walker, in some of his claims, e.g., claims 2 and 3, does describe the tuned acoustical pipe as an integral part of his invention, showing its structure, its working arrangement in the alleged new combination, and the manner of its connection with the other parts. But no one of the claims on which this judgment rests has even suggested the physical structure of the acoustical resonator. 6\\n No one of these claims describes the physical relation of the Walker addition to the old Lehr and Wyatt machine. No one of these claims describes the manner in which the Walker addition will operate together with the old Lehr and Wyatt machine so as to make the \\'new\\' unitary apparatus perform its designed function. Thus the claims failed adequately to depict the structure, mode, and operation of the parts in combination.\\n A claim typical of all of those held valid only describes the resonator and its relation with the rest of the apparatus as \\'means associated with said pressure responsive device for tuning said receiving means to the frequency of echoes from the tubing collars of said tubing section to clearly distinguish the echoes of said couplings from each other.\\' 7\\n The language of the claim thus describes this most crucial element in the \\'new\\' combination in terms of what it will do rather than in terms of its own physical characteristics or its arrangement in the new combination apparatus. We have held that a claim with such a description of a product is invalid as a violation of Rev.Stat. 4888. Holland Furniture Co. v. Perkins Glue Co., , 257 S., 48 S.Ct. 474, 478, 479; General Electric Co. v. Wabash Appliance Corporation, supra. We understand that the circuit court of appeals held that the same rigid standards of description required for product claims is not required for a combination patent embodying old elements only. We have a different view.\\n Rev.Stat. 4888 pointedly provides that \\'in the case of a machine, he (the patentee) shall explain the principle thereof, and the best mode in which he has contemplated applying that principle, so as to distinguish it from other inventions; and he shall particularly point out and distinctively claim the part, improvement, or combination which he claims as his invention or discovery.\\' It has long been held that the word \\'machine\\' includes a combination. Corning et al. v. Burden, 15 How. 252, 267. We are not persuaded that the public and those affected by patents should lose the protection of this statute merely because the patented device is a combination of old elements.\\n Patents on machines which join old and well-known devices with the declared object of achieving new results, or patents which add an old element to improve a preexisting combination, easily lend themselves to abuse. And to prevent extension of a patent\\'s scope beyond what was actually invented, courts have viewed claims to combinations and improvements or additions to them with very close scrutiny. Cf. Lincoln Engineering Co. of Illinois v. Stewart Warner Corporation, , 549-551, 58 S.Ct. 662. For the same reason, courts have qualified the scope of what is meant by the equivalent of an ingredient of a combination of old elements. Gill v. Wells, 22 Wall. 1, 28, 29. Fuller v. Yentzer, , 298 S.. It is quite consistent with this strict interpretation of patents for machines which combine old elements to require clear description in combination claims. This view, clearly expressed in Gill v. Wells, supra, is that\\n\\'Where the ingredients are all old the invention ... consists entirely in the combination, and the requirement of the Patent Act that the invention shall be fully and exactly described applies with as much force to such an invention as to any other class, because if not fulfilled all three of the great ends intended to be accomplished by that requirement would be defeated. ... (1.) That the Government may know what they have granted and what will become public property when the term of the monopoly expires. (2.) That licensed persons desiring to practice the invention may know, during the term, how to make, construct, and use the invention. (3.) That other inventors may know what part of the field of invention is unoccupied.\\n\\'Purposes such as these are of great importance in every case, but the fulfillment of them is never more necessary than when such inquiries arise in respect to a patent for a machine which consists of a combination of old ingredients. Patents of that kind are much more numerous than any other, and consequently it is of the greatest importance that the description of the combination, which is the invention, should be full, clear, concise, and exact.\\' Gill v. Wells, supra, 22 Wall. at pages 25, 26.\\n These principles were again emphasized in Merrill v. Yeomans, , 570, where it was said that \\'... in cases where the invention is a new combination of old devices, he (the patentee) is bound to describe with particularity all these old devices, and then the new mode of combining them, for which he desires a patent.\\' This view has most recently been reiterated in General Electric Co. v. Wabash Appliance Corporation, supraat pages 368, 369, 58 S.Ct. at pages 901, 902. Cogent reasons would have to be presented to persuade us to depart from this established doctrine. The facts of the case before us, far from undermining our confidence in these earlier pronouncements, reinforce the conclusion that the statutory requirement for a clear description of claims applies to a combination of old devices.\\n This patent and the infringement proceedings brought under it illustrate the hazards of carving out an exception to the sweeping demand Congress made in Rev.Stat. 4888. Neither in the specification, the drawing, nor in the claims here under consideration, was there any indication that the patentee contemplated any specific structural alternative for the acoustical resonator or for the resonator\\'s relationship to the other parts of the machine. Petitioner was working in a field crowded almost, if not completely, to the point of exhaustion. In 1920, Tucker, in Patent No. 1,451,356, had shown a tuned acoustical resonator in a sound detecting device which measured distances. Lehr and Wyatt had provided for amplification of their waves. Sufficient amplification and exaggeration of all the differ- ent waves which Lehr and Wyatt recorded on their machine would have made it easy to distinguish the tubing catcher and regular shoulder waves from all others. For, even without this amplification, the echo waves from tubing collars could by proper magnification have been recorded and accurately counted, had Lehr and Wyatt recognized their importance in computing the velocity. Cf. General Electric Co. v. Jewel Incandescent Lamp Co., .\\n Under these circumstances the broadness, ambiguity, and overhanging threat of the functional claim of Walker become apparent. What he claimed in the court below and what he claims here is that his patent bars anyone from using in an oil well any device heretofore or hereafter invented which combined with the Lehr and Wyatt machine performs the function of clearly and distinctly catching and recording echoes from tubing joints with regularity. Just how many different devices there are of various kinds and characters which would serve to emphasize these echoes, we do not know. The Halliburton device, alleged to infringe, employs an electric filter for this purpose. In this age of technological development there may be many other devices beyond our present information or indeed our imagination which will perform that function and yet fit these claims. And unless frightened from the course of experimentation by broad functional claims like these, inventive genius may evolve many more devices to accomplish the same purpose. See United Carbon Co. et al. v. Binney & Smith Co., ; Burr v. Duryee, 1 Wall. 531, 568; O\\'Reilly et al. v. Morse et al., 15 How. 62, 112, 113. Yet if Walker\\'s blanket claims be valid, no device to clarify echo waves, now known or hereafter invented, whether the device be an actual equivalent of Walker\\'s ingredient or not, could be used in a combination such as this, during the life of Walker\\'s patent. Had Walker accurately described the machine he claims to have invented, he would have had no such broad rights to bar the use of all devices now or hereafter known which could accent waves. For had he accurately described the resonator together with the Lehr and Wyatt apparatus, and sued for infringement, charging the use of something else used in combination to accent the waves, the alleged infringer could have prevailed if the substituted device (1) performed a substantially different function; (2) was not known at the date of Walker\\'s patent as a proper substitute for the resonator; or (3) had been actually invented after the date of the patent. Fuller v. Yentzer, supraat pages 296, 297; Gill v. Wells, supra, 22 Wall. at page 29. Certainly, if we are to be consistent with Rev.Stat. 4888, a patentee cannot obtain greater coverage by failing to describe his invention than by describing it as the statute commands.\\n It is urged that our conclusion is in conflict with the decision of Continental Paper Bag Co. v. Eastern Paper Bag Co., . In that case, however, the claims structurally described the physical and operating relationship of all the crucial parts of the novel combination. 8\\n The court there decided only that there had been an infringement of this adequately described invention. That case is not authority for sustaining the claims before us which fail adequately to describe the alleged invention.\\nREVERSED.\\n Mr. Justice FRANKFURTER concurs with the Court\\'s opinion in so far as it finds this claim lacking in the definiteness required by Rev.Stat. 4888, 35 U.S.C. 33, 35 U.S.C.A. 33, but reserves judgment as to considerations that may be peculiar to combination patents in satisfying that requirement.\\n Mr. Justice BURTON dissents. Footnotes\\n[\\nFootnote 1\\n] \\'33. Application for Patent; Description; Specification and Claim. Before any inventor or discoverer shall receive a patent for his invention or discovery he shall make application therefor, in writing, to the Commissioner of Patents, and shall file in the Patent Office a written description of the same, and of the manner and process of making, constructing, compounding, and using it, in such full, clear, concise, and exact terms as to enable any person skilled in the art or science to which it appertains, or with which it is most nearly connected, to make, construct, compound, and use the same; and in case of a machine, he shall explain the principle thereof, and the best mode in which he has contemplated applying that principle, so as to distinguish it from other inventions; and he shall particularly point out and distinctly claim the part, improvement, or combination which he claims as his invention or discovery. ...\\' [\\nFootnote 2\\n] Other alleged errors were urged in the application for certiorari and have been argued here, but since we find the question of definiteness of the claim decisive of the controversy, we shall not further advert to the other contentions. [\\nFootnote 3\\n] This case was previously affirmed by a divided court, and upon petition for rehearing was restored to the docket for reargument. . [\\nFootnote 4\\n] The known distance from well top to the tubing catcher is to the unknown distance from well top to the fluid surface as the time an echo requires to travel from the tubing catcher is to the time required for an echo to travel from the fluid surface.\\n Walker\\'s patent emphasizes that his invention solves the velocity of sound waves in wells of various pressures in which sound did not travel at open-air or a uniform speed. Mathematically, of course, his determination of the distance by proportions determines the distance to the fluid surface directly without necessarily considering velocity in feet per second as a factor. [\\nFootnote 5\\n] See Hailes v. Van Wormer, 20 Wall. 353; Knapp v. Morss, , 228 S., 14 S.Ct. 81, 83, 84; Textile Machine Works v. Louis Hirsch Textile Machines, Inc., , 58 S. Ct. 291; Lincoln Engineering Co. of Illinois v. Stewart- Warner Corp., , 550 S., 58 S.Ct. 662, 664, 665. [\\nFootnote 6\\n] Halliburton does not challenge the adequacy of the description of any other features of the \\'new combination.\\' The elements of Walker\\'s apparatus other than the filter are so nearly identical to what Lehr and Wyatt patented that we can speak of these other elements as the \\'Lehr and Wyatt machine.\\' [\\nFootnote 7\\n] Both parties have used Claim 1 as a typical example for purposes of argument throughout the litigation. Other claims need not be set out. Claim 1 is as follows: \\'In an apparatus for determining the location of an obstruction in a well having therein a string of assembling tubing sections inter-connected with each other by coupling collars, means communicating with said well for creating a pressure impulse in said well, echo receiving means including a pressure responsive device exposed to said well for receiving pressure impulses from the well and for measuring the lapse of time between the creation of the impulse and the arrival at said receiving means of the echo from said obstruction, and means associated with said pressure responsive device for tuning said receiving means to the frequency of echoes from the tubing collars of said tubing sections to clearly distinguish the echoes from said couplings from each other.\\' [\\nFootnote 8\\n] The typical claim there in suit was as follows: \\'2. In a paper bag machine, the combination of the rotating cylinder provided with one or more pairs of sidefolding fingers adapted to be moved toward or from each other, a forming plate also provided with side-forming fingers adapted to be moved toward or from each other, means for operating said fingers at definite times during the formative action upon the bag tube, operating means for the forming plate adapted to cause the said plate to oscillate about its rear edge upon the surface of the cylinder during the rotary movement of said cylinder for the purpose of opening and forming the bottom of the bag tube, a finger moving with the forming plate for receiving the upper sheet of the tube and lifting it during the formative action, power devices for returning the forming plate to its original position to receive a new bag tube, and means to move the bag tube with the cylinder.\\' Continental Paper Bag Co. v. Eastern Paper Bag Co., , 417, n. 1, 28 S.Ct. 748, 750.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Found 173087 unique tokens.\n",
      "Shape of padded_data ndarray: (8419, 90018)\n",
      "Shape of label ndarray: (8419, 15)\n"
     ]
    }
   ],
   "source": [
    "# vectorize the text samples into a 2D integer tensor\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "print(type(sequences))\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "# with tf.device('/gpu:0'):\n",
    "padded_data = pad_sequences(sequences)\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = padded_data.shape[1]\n",
    "\n",
    "labels = to_categorical(np.asarray(labels))\n",
    "    \n",
    "print('Shape of padded_data ndarray:', padded_data.shape)\n",
    "print('Shape of label ndarray:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare embedding matrix -> tensor\n",
    "num_words = min(MAX_NB_WORDS, len(word_index))\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NB_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a training set and a validation set\n",
    "x_train_ndarray, x_test_ndarray, y_train_ndarray, y_test_ndarray = train_test_split(padded_data, labels, test_size=VALIDATION_SPLIT, random_state=42)\n",
    "x_train_ndarray, x_val_ndarray, y_train_ndarray, y_val_ndarray = train_test_split(x_train_ndarray, y_train_ndarray, test_size=VALIDATION_SPLIT, random_state=42)\n",
    "\n",
    "# to tensor and to gpu\n",
    "x_train = torch.from_numpy(x_train_ndarray).to(device, dtype=torch.long)\n",
    "# x_train = x_train.unsqueeze(1)\n",
    "y_train = torch.from_numpy(y_train_ndarray).to(device, dtype=torch.long)\n",
    "\n",
    "x_val = torch.from_numpy(x_val_ndarray).to(device, dtype=torch.long)\n",
    "# x_val = x_val.unsqueeze(1)\n",
    "y_val = torch.from_numpy(y_val_ndarray).to(device, dtype=torch.long)\n",
    "\n",
    "x_test = torch.from_numpy(x_test_ndarray).to(device, dtype=torch.long)\n",
    "# x_test = x_test.unsqueeze(1)\n",
    "y_test = torch.from_numpy(y_test_ndarray).to(device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "dataset_train = data.TensorDataset(x_train,y_train)\n",
    "dataloader_train = data.DataLoader(dataset_train, batch_size=4, shuffle=True)\n",
    "dataset_val = data.TensorDataset(x_val,y_val)\n",
    "dataloader_val = data.DataLoader(dataset_val, batch_size=4, shuffle=False)\n",
    "dataset_test = data.TensorDataset(x_test,y_test)\n",
    "dataloader_test = data.DataLoader(dataset_test, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 90018])\n",
      "torch.Size([4, 15])\n"
     ]
    }
   ],
   "source": [
    "dataiter_temp = iter(dataloader_train)\n",
    "images_temp, labels_temp = dataiter_temp.next()\n",
    "# images_temp = images_temp.unsqueeze(1)\n",
    "print(images_temp.size())\n",
    "print(labels_temp.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_words, EMBEDDING_DIM)\n",
    "        self.embedding.weight = nn.Parameter(torch.from_numpy(embedding_matrix).float())\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        self.conv_module = nn.Sequential(\n",
    "            \n",
    "            nn.Conv1d(300,128,5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(5),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Conv1d(128,128,5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(5),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Conv1d(128,128,5),\n",
    "            nn.ReLU(),\n",
    "#             nn.MaxPool1d(128),\n",
    "            nn.Dropout(0.5),\n",
    "                \n",
    "        )\n",
    "        \n",
    "        self.dense_module = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "#             nn.Dropout(0.5),\n",
    "            nn.Linear(128, len(labels_index)),\n",
    "#             nn.Softmax()\n",
    "        )\n",
    "\n",
    "#         self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "#         self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "#         self.fc2 = nn.Linear(120, 84)\n",
    "#         self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        x = self.conv_module(x)\n",
    "#         print('after conv: ', x.size())\n",
    "        x, _  = torch.max(x, 2) # global max pooling\n",
    "#         print('after max: ', x.size())\n",
    "        x = self.dense_module(x)\n",
    "        \n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = x.view(-1, 16 * 5 * 5)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.cuda.FloatTensor'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.embedding.weight.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (embedding): Embedding(170000, 300)\n",
       "  (conv_module): Sequential(\n",
       "    (0): Conv1d(300, 128, kernel_size=(5,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.25, inplace=False)\n",
       "    (4): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Dropout(p=0.25, inplace=False)\n",
       "    (8): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
       "    (9): ReLU()\n",
       "    (10): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (dense_module): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=15, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(device)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   400] loss: 0.283\n",
      "[1,   800] loss: 0.273\n",
      "[1,  1200] loss: 0.247\n",
      "[1,  1600] loss: 0.239\n",
      "-------------- testing --------------\n",
      "Accuracy: 61.757720 %\n",
      "[2,   400] loss: 0.231\n",
      "[2,   800] loss: 0.232\n",
      "[2,  1200] loss: 0.224\n",
      "[2,  1600] loss: 0.223\n",
      "-------------- testing --------------\n",
      "Accuracy: 62.589074 %\n",
      "[3,   400] loss: 0.217\n",
      "[3,   800] loss: 0.203\n",
      "[3,  1200] loss: 0.213\n",
      "[3,  1600] loss: 0.217\n",
      "-------------- testing --------------\n",
      "Accuracy: 64.845606 %\n",
      "[4,   400] loss: 0.198\n",
      "[4,   800] loss: 0.197\n",
      "[4,  1200] loss: 0.203\n",
      "[4,  1600] loss: 0.201\n",
      "-------------- testing --------------\n",
      "Accuracy: 66.983373 %\n",
      "[5,   400] loss: 0.187\n",
      "[5,   800] loss: 0.185\n",
      "[5,  1200] loss: 0.195\n",
      "[5,  1600] loss: 0.178\n",
      "-------------- testing --------------\n",
      "Accuracy: 65.083135 %\n",
      "[6,   400] loss: 0.176\n",
      "[6,   800] loss: 0.179\n",
      "[6,  1200] loss: 0.180\n",
      "[6,  1600] loss: 0.169\n",
      "-------------- testing --------------\n",
      "Accuracy: 68.764846 %\n",
      "[7,   400] loss: 0.165\n",
      "[7,   800] loss: 0.162\n",
      "[7,  1200] loss: 0.165\n",
      "[7,  1600] loss: 0.164\n",
      "-------------- testing --------------\n",
      "Accuracy: 69.358670 %\n",
      "[8,   400] loss: 0.156\n",
      "[8,   800] loss: 0.148\n",
      "[8,  1200] loss: 0.148\n",
      "[8,  1600] loss: 0.155\n",
      "-------------- testing --------------\n",
      "Accuracy: 69.002375 %\n",
      "[9,   400] loss: 0.143\n",
      "[9,   800] loss: 0.139\n",
      "[9,  1200] loss: 0.138\n",
      "[9,  1600] loss: 0.133\n",
      "-------------- testing --------------\n",
      "Accuracy: 70.546318 %\n",
      "[10,   400] loss: 0.133\n",
      "[10,   800] loss: 0.117\n",
      "[10,  1200] loss: 0.133\n",
      "[10,  1600] loss: 0.123\n",
      "-------------- testing --------------\n",
      "Accuracy: 67.933492 %\n",
      "[11,   400] loss: 0.120\n",
      "[11,   800] loss: 0.112\n",
      "[11,  1200] loss: 0.111\n",
      "[11,  1600] loss: 0.118\n",
      "-------------- testing --------------\n",
      "Accuracy: 71.733967 %\n",
      "[12,   400] loss: 0.101\n",
      "[12,   800] loss: 0.109\n",
      "[12,  1200] loss: 0.102\n",
      "[12,  1600] loss: 0.104\n",
      "-------------- testing --------------\n",
      "Accuracy: 70.071259 %\n",
      "[13,   400] loss: 0.090\n",
      "[13,   800] loss: 0.093\n",
      "[13,  1200] loss: 0.090\n",
      "[13,  1600] loss: 0.095\n",
      "-------------- testing --------------\n",
      "Accuracy: 71.971496 %\n",
      "[14,   400] loss: 0.077\n",
      "[14,   800] loss: 0.073\n",
      "[14,  1200] loss: 0.086\n",
      "[14,  1600] loss: 0.082\n",
      "-------------- testing --------------\n",
      "Accuracy: 74.465558 %\n",
      "[15,   400] loss: 0.062\n",
      "[15,   800] loss: 0.069\n",
      "[15,  1200] loss: 0.073\n",
      "[15,  1600] loss: 0.071\n",
      "-------------- testing --------------\n",
      "Accuracy: 71.615202 %\n",
      "[16,   400] loss: 0.052\n",
      "[16,   800] loss: 0.061\n",
      "[16,  1200] loss: 0.064\n",
      "[16,  1600] loss: 0.065\n",
      "-------------- testing --------------\n",
      "Accuracy: 73.277910 %\n",
      "[17,   400] loss: 0.047\n",
      "[17,   800] loss: 0.052\n",
      "[17,  1200] loss: 0.051\n",
      "[17,  1600] loss: 0.057\n",
      "-------------- testing --------------\n",
      "Accuracy: 72.090261 %\n",
      "[18,   400] loss: 0.043\n",
      "[18,   800] loss: 0.041\n",
      "[18,  1200] loss: 0.049\n",
      "[18,  1600] loss: 0.046\n",
      "-------------- testing --------------\n",
      "Accuracy: 73.277910 %\n",
      "[19,   400] loss: 0.036\n",
      "[19,   800] loss: 0.041\n",
      "[19,  1200] loss: 0.036\n",
      "[19,  1600] loss: 0.046\n",
      "-------------- testing --------------\n",
      "Accuracy: 72.446556 %\n",
      "[20,   400] loss: 0.028\n",
      "[20,   800] loss: 0.036\n",
      "[20,  1200] loss: 0.035\n",
      "[20,  1600] loss: 0.032\n",
      "-------------- testing --------------\n",
      "Accuracy: 71.615202 %\n",
      "[21,   400] loss: 0.034\n",
      "[21,   800] loss: 0.029\n",
      "[21,  1200] loss: 0.030\n",
      "[21,  1600] loss: 0.032\n",
      "-------------- testing --------------\n",
      "Accuracy: 71.852732 %\n",
      "[22,   400] loss: 0.024\n",
      "[22,   800] loss: 0.018\n",
      "[22,  1200] loss: 0.033\n",
      "[22,  1600] loss: 0.028\n",
      "-------------- testing --------------\n",
      "Accuracy: 70.071259 %\n",
      "[23,   400] loss: 0.020\n",
      "[23,   800] loss: 0.028\n",
      "[23,  1200] loss: 0.029\n",
      "[23,  1600] loss: 0.025\n",
      "-------------- testing --------------\n",
      "Accuracy: 73.871734 %\n",
      "[24,   400] loss: 0.023\n",
      "[24,   800] loss: 0.023\n",
      "[24,  1200] loss: 0.027\n",
      "[24,  1600] loss: 0.022\n",
      "-------------- testing --------------\n",
      "Accuracy: 73.871734 %\n",
      "[25,   400] loss: 0.017\n",
      "[25,   800] loss: 0.020\n",
      "[25,  1200] loss: 0.024\n",
      "[25,  1600] loss: 0.029\n",
      "-------------- testing --------------\n",
      "Accuracy: 74.346793 %\n",
      "[26,   400] loss: 0.016\n",
      "[26,   800] loss: 0.013\n",
      "[26,  1200] loss: 0.025\n",
      "[26,  1600] loss: 0.026\n",
      "-------------- testing --------------\n",
      "Accuracy: 74.109264 %\n",
      "[27,   400] loss: 0.017\n",
      "[27,   800] loss: 0.019\n",
      "[27,  1200] loss: 0.016\n",
      "[27,  1600] loss: 0.023\n",
      "-------------- testing --------------\n",
      "Accuracy: 73.634204 %\n",
      "[28,   400] loss: 0.019\n",
      "[28,   800] loss: 0.020\n",
      "[28,  1200] loss: 0.026\n",
      "[28,  1600] loss: 0.016\n",
      "-------------- testing --------------\n",
      "Accuracy: 73.634204 %\n",
      "[29,   400] loss: 0.012\n",
      "[29,   800] loss: 0.021\n",
      "[29,  1200] loss: 0.019\n",
      "[29,  1600] loss: 0.017\n",
      "-------------- testing --------------\n",
      "Accuracy: 74.109264 %\n",
      "[30,   400] loss: 0.012\n",
      "[30,   800] loss: 0.017\n",
      "[30,  1200] loss: 0.018\n",
      "[30,  1600] loss: 0.025\n",
      "-------------- testing --------------\n",
      "Accuracy: 74.228029 %\n",
      "[31,   400] loss: 0.014\n",
      "[31,   800] loss: 0.013\n",
      "[31,  1200] loss: 0.019\n",
      "[31,  1600] loss: 0.021\n",
      "-------------- testing --------------\n",
      "Accuracy: 73.396675 %\n",
      "[32,   400] loss: 0.014\n",
      "[32,   800] loss: 0.013\n",
      "[32,  1200] loss: 0.021\n",
      "[32,  1600] loss: 0.019\n",
      "-------------- testing --------------\n",
      "Accuracy: 75.059382 %\n",
      "[33,   400] loss: 0.013\n",
      "[33,   800] loss: 0.019\n",
      "[33,  1200] loss: 0.017\n",
      "[33,  1600] loss: 0.012\n",
      "-------------- testing --------------\n",
      "Accuracy: 70.190024 %\n",
      "[34,   400] loss: 0.015\n",
      "[34,   800] loss: 0.013\n",
      "[34,  1200] loss: 0.015\n",
      "[34,  1600] loss: 0.012\n",
      "-------------- testing --------------\n",
      "Accuracy: 74.821853 %\n",
      "[35,   400] loss: 0.014\n",
      "[35,   800] loss: 0.016\n",
      "[35,  1200] loss: 0.018\n",
      "[35,  1600] loss: 0.012\n",
      "-------------- testing --------------\n",
      "Accuracy: 73.159145 %\n",
      "[36,   400] loss: 0.010\n",
      "[36,   800] loss: 0.017\n",
      "[36,  1200] loss: 0.015\n",
      "[36,  1600] loss: 0.016\n",
      "-------------- testing --------------\n",
      "Accuracy: 73.990499 %\n",
      "[37,   400] loss: 0.010\n",
      "[37,   800] loss: 0.015\n",
      "[37,  1200] loss: 0.013\n",
      "[37,  1600] loss: 0.012\n",
      "-------------- testing --------------\n",
      "Accuracy: 73.277910 %\n",
      "[38,   400] loss: 0.012\n",
      "[38,   800] loss: 0.017\n",
      "[38,  1200] loss: 0.014\n",
      "[38,  1600] loss: 0.013\n",
      "-------------- testing --------------\n",
      "Accuracy: 73.040380 %\n",
      "[39,   400] loss: 0.012\n",
      "[39,   800] loss: 0.010\n",
      "[39,  1200] loss: 0.015\n",
      "[39,  1600] loss: 0.014\n",
      "-------------- testing --------------\n",
      "Accuracy: 73.396675 %\n",
      "[40,   400] loss: 0.012\n",
      "[40,   800] loss: 0.011\n",
      "[40,  1200] loss: 0.012\n",
      "[40,  1600] loss: 0.013\n",
      "-------------- testing --------------\n",
      "Accuracy: 74.584323 %\n",
      "[41,   400] loss: 0.006\n",
      "[41,   800] loss: 0.010\n",
      "[41,  1200] loss: 0.013\n",
      "[41,  1600] loss: 0.014\n",
      "-------------- testing --------------\n",
      "Accuracy: 74.940618 %\n",
      "[42,   400] loss: 0.017\n",
      "[42,   800] loss: 0.018\n",
      "[42,  1200] loss: 0.009\n",
      "[42,  1600] loss: 0.014\n",
      "-------------- testing --------------\n",
      "Accuracy: 73.990499 %\n",
      "[43,   400] loss: 0.010\n",
      "[43,   800] loss: 0.014\n",
      "[43,  1200] loss: 0.011\n",
      "[43,  1600] loss: 0.010\n",
      "-------------- testing --------------\n",
      "Accuracy: 72.327791 %\n",
      "[44,   400] loss: 0.013\n",
      "[44,   800] loss: 0.009\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "    \n",
    "    # train\n",
    "    running_loss = 0.0\n",
    "    for i, data_train in enumerate(dataloader_train, 0):\n",
    "        net.train()\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs_train, labels_train = data_train\n",
    "#         print(inputs_train.size())\n",
    "#         print(labels_train.size())\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs_train = net(inputs_train)\n",
    "#         print(outputs_train.size())\n",
    "#         print(labels_train.size())\n",
    "#         print(torch.max(labels_train, 1)[1])\n",
    "#         print('outputs_train: ', outputs_train)\n",
    "        \n",
    "        loss = criterion(outputs_train, torch.max(labels_train, 1)[1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if (i+1) % 400 == 0:    # print every 400 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # test\n",
    "    if epoch % 1 == 0:\n",
    "        print('-------------- testing --------------')\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        net.eval()\n",
    "#         with torch.no_grad():\n",
    "#         for data_test in dataloader_test:\n",
    "        for data_test in dataloader_test:\n",
    "            images_test, labels_test = data_test\n",
    "            outputs_test = net(images_test)\n",
    "            _, outputs_test = torch.max(outputs_test, 1) # get the class index\n",
    "            _, labels_test = torch.max(labels_test, 1)\n",
    "#                 print('outputs_test: ', outputs_test)\n",
    "#                 print('labels_test: ', labels_test)\n",
    "#                 print((outputs_test == labels_test).sum().item())\n",
    "\n",
    "            total += labels_test.size(0)\n",
    "            correct += (outputs_test == labels_test).sum().item()\n",
    "        print('Accuracy: %f %%' % (100 * correct / total))\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "\n",
    "    if not os.path.exists(model_checkPoint_path):\n",
    "        os.makedirs(model_checkPoint_path)\n",
    "\n",
    "#     MAX_SEQUENCE_LENGTH = 90018\n",
    "\n",
    "    # split the data into a training set and a validation set\n",
    "#     with tf.device('/device:GPU:0'):\n",
    "#     x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=VALIDATION_SPLIT, random_state=42)\n",
    "#     x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=VALIDATION_SPLIT, random_state=42)\n",
    "#     print(x_train)\n",
    "\n",
    "#     def generator():\n",
    "#         while True:\n",
    "#             indices = list(range(len(x_train)))\n",
    "#             imax = len(indices)//BATCH_SIZE\n",
    "#             for i in range(imax):\n",
    "#                 list_IDs_temp = indices[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "#                 yield x_train[list_IDs_temp], y_train[list_IDs_temp]\n",
    "\n",
    "#     def test_generator():\n",
    "#         while True:\n",
    "#             indices = list(range(len(x_test)))\n",
    "#             imax = len(indices)//BATCH_SIZE\n",
    "#             for i in range(imax):\n",
    "#                 list_IDs_temp = indices[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "#                 yield x_test[list_IDs_temp], y_test[list_IDs_temp]\n",
    "\n",
    "#     def val_generator():\n",
    "#         while True:\n",
    "#             indices = list(range(len(x_val)))\n",
    "#             imax = len(indices)//BATCH_SIZE\n",
    "#             for i in range(imax):\n",
    "#                 list_IDs_temp = indices[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "#                 yield x_val[list_IDs_temp], y_val[list_IDs_temp]\n",
    "\n",
    "\n",
    "    print('Training model.')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "      Embedding(num_words,\n",
    "                EMBEDDING_DIM,\n",
    "                weights=[embedding_matrix],\n",
    "                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                trainable=False)\n",
    "    )\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv1D(128, 5, activation='relu'))\n",
    "    model.add(MaxPooling1D(5))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv1D(128, 5, activation='relu'))\n",
    "    model.add(MaxPooling1D(5))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv1D(128, 5, activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(len(labels_index), activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'])\n",
    "    \n",
    "    # os.path.basename(__file__)[:-3]\n",
    "    checkpointer = ModelCheckpoint(filepath = model_checkPoint_path + 'cnn15' +\n",
    "        \"-{epoch:02d}-{val_acc:.2f}.hdf5\",\n",
    "                                   monitor='val_acc',\n",
    "                                   verbose=2,\n",
    "                                   save_best_only=True,\n",
    "                                   mode='max')\n",
    "\n",
    "    earlystopper = EarlyStopping(monitor='val_loss',\n",
    "                             min_delta=0,\n",
    "                             patience=0,\n",
    "                             verbose=2,\n",
    "                             mode='auto')\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.fit_generator(generator=generator(),\n",
    "                        steps_per_epoch = len(x_train)//BATCH_SIZE,\n",
    "                        epochs=50,\n",
    "                        verbose=1,\n",
    "                        validation_data=test_generator(),\n",
    "                        validation_steps=len(x_test)//BATCH_SIZE,\n",
    "                        callbacks=[checkpointer, earlystopper],\n",
    "                        shuffle=True)\n",
    "    \n",
    "#     model.fit(x_train, y_train,\n",
    "#                 steps_per_epoch = len(x_train)//BATCH_SIZE,\n",
    "#                 epochs=50,\n",
    "#                 verbose=1,\n",
    "#                 validation_data=(x_val, y_val),\n",
    "#                 validation_steps=len(x_test)//BATCH_SIZE,\n",
    "#                 callbacks=[checkpointer, earlystopper],\n",
    "#                 shuffle=True)\n",
    "    \n",
    "    score = model.evaluate_generator(val_generator(),\n",
    "                                     steps=len(x_val)//BATCH_SIZE)\n",
    "\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    # Save Keras ModelCheckpoints locally\n",
    "    model.save('model.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0 ...  1364     3  2830]\n",
      " [    0     0     0 ...  1362  2324  1214]\n",
      " [    0     0     0 ...   374     7  2969]\n",
      " ...\n",
      " [    0     0     0 ...    14 13615   470]\n",
      " [    0     0     0 ...    63  2435     4]\n",
      " [    0     0     0 ...     8   297   186]]\n",
      "Training model.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 90018, 300)        51000000  \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 90018, 300)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 90014, 128)        192128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 18002, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 18002, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 17998, 128)        82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 3599, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 3599, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 3595, 128)         82048     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 15)                1935      \n",
      "=================================================================\n",
      "Total params: 51,374,671\n",
      "Trainable params: 374,671\n",
      "Non-trainable params: 51,000,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      " 80/213 [==========>...................] - ETA: 26:48 - loss: 2.3253 - acc: 0.2023"
     ]
    }
   ],
   "source": [
    "# if __name__ == '__main__':\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
